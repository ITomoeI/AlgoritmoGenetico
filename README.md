# Librer√≠a de Algoritmos Gen√©ticos para Optimizaci√≥n

[![PyPI version](https://img.shields.io/badge/testpypi-v0.1.0-blue)](https://test.pypi.org/project/algoritmo-genetico-itomoei/)
[![Python 3.6+](https://img.shields.io/badge/python-3.6+-green.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Una implementaci√≥n robusta y flexible de algoritmos gen√©ticos para optimizaci√≥n de funciones matem√°ticas en Python.

## üìã Tabla de Contenidos

- [Introducci√≥n](#introducci√≥n)
- [Conceptos B√°sicos](#conceptos-b√°sicos)
- [Instalaci√≥n](#instalaci√≥n)
- [Estructura de la Librer√≠a](#estructura-de-la-librer√≠a)
- [Gu√≠a de Uso](#gu√≠a-de-uso)
- [Ejemplos](#ejemplos)
- [API de Referencia](#api-de-referencia)
- [Ajuste de Par√°metros](#ajuste-de-par√°metros)
- [Casos de Uso Avanzados](#casos-de-uso-avanzados)
- [Visualizaciones](#visualizaciones)
- [Contribuir](#contribuir)
- [Autores](#autores)
- [Licencia](#licencia)

## üß¨ Introducci√≥n

Los algoritmos gen√©ticos (AG) son m√©todos de optimizaci√≥n inspirados en la selecci√≥n natural y la gen√©tica. Esta librer√≠a proporciona una implementaci√≥n completa para encontrar soluciones √≥ptimas a problemas matem√°ticos complejos.

### ¬øQu√© problemas puede resolver?

- Encontrar m√≠nimos o m√°ximos de funciones matem√°ticas
- Optimizar funciones con una o m√∫ltiples variables
- Resolver problemas donde las t√©cnicas de c√°lculo tradicionales fallan
- Explorar espacios de b√∫squeda complejos con m√∫ltiples √≥ptimos locales

## üîç Conceptos B√°sicos

### Componentes clave del algoritmo gen√©tico:

1. **Cromosoma/Individuo**: Soluci√≥n potencial al problema
2. **Poblaci√≥n**: Conjunto de individuos
3. **Funci√≥n Objetivo**: Eval√∫a la calidad de una soluci√≥n
4. **Selecci√≥n**: Proceso de elegir individuos para reproducci√≥n
5. **Cruce**: Combinaci√≥n de material gen√©tico entre individuos
6. **Mutaci√≥n**: Alteraci√≥n aleatoria de genes
7. **Convergencia**: Proceso por el cual la poblaci√≥n evoluciona hacia una soluci√≥n √≥ptima

### Flujo del algoritmo:

1. Inicializar poblaci√≥n aleatoria
2. Evaluar cada individuo mediante la funci√≥n objetivo
3. Seleccionar individuos para reproducci√≥n
4. Aplicar operadores gen√©ticos (cruce y mutaci√≥n)
5. Reemplazar la poblaci√≥n antigua con la nueva
6. Repetir hasta alcanzar criterio de parada

## ‚öôÔ∏è Instalaci√≥n

### Desde TestPyPI

```bash
# Instalar la librer√≠a
pip install --index-url https://test.pypi.org/simple/ --no-deps algoritmo_genetico_itomoei

# Instalar dependencias
pip install numpy
```

### Desde GitHub

```bash
# Clonar el repositorio
git clone https://github.com/ITomoeI/AlgoritmoGenetico.git

# Entrar al directorio
cd AlgoritmoGenetico

# Instalar en modo desarrollo
pip install -e .
```

### Requisitos
- Python 3.6+
- NumPy

## üèóÔ∏è Estructura de la Librer√≠a

La librer√≠a se organiza de la siguiente manera:

```
genetic_algorithm/
‚îú‚îÄ‚îÄ __init__.py           # Expone las funciones principales
‚îî‚îÄ‚îÄ functions.py          # Implementaci√≥n de las funciones del algoritmo
```

### Componentes principales:

- `crear_individuo`: Genera una soluci√≥n candidata aleatoria
- `crear_poblacion`: Inicializa una poblaci√≥n de individuos
- `evaluar_poblacion`: Calcula la aptitud de cada individuo
- `seleccion_torneo`: Selecciona individuos mediante torneos
- `cruce`: Combina genes de dos padres
- `mutacion`: Altera aleatoriamente los genes
- `algoritmo_genetico`: Funci√≥n principal que orquesta todo el proceso

## üìò Gu√≠a de Uso

### Uso b√°sico

```python
from genetic_algorithm import algoritmo_genetico

# Definir la funci√≥n a optimizar
def funcion_objetivo(x):
    return x[0]**2  # Minimizar x^2

# Ejecutar el algoritmo gen√©tico
resultado = algoritmo_genetico(
    funcion_objetivo=funcion_objetivo,
    dimensiones=1,  # Una variable
    limites=[(-10, 10)],  # Rango de b√∫squeda
    tamano_poblacion=50,
    max_generaciones=100,
    verbose=True  # Mostrar progreso
)

# Obtener resultados
print(f"Mejor soluci√≥n: {resultado['mejor_solucion']}")
print(f"Mejor valor: {resultado['mejor_valor']}")
```

### Modo minimizaci√≥n vs maximizaci√≥n

Por defecto, el algoritmo busca minimizar la funci√≥n objetivo. Para maximizar:

```python
# Maximizar f(x) = -(x-5)^2 + 25 (m√°ximo en x=5)
def funcion_objetivo(x):
    return -(x[0]-5)**2 + 25

resultado = algoritmo_genetico(
    funcion_objetivo=funcion_objetivo,
    dimensiones=1,
    limites=[(-10, 10)],
    minimizar=False  # Indicamos maximizaci√≥n
)
```

### Optimizaci√≥n multivariable

```python
# Minimizar funci√≥n de Rosenbrock
def rosenbrock(variables):
    x, y = variables
    return (1 - x)**2 + 100 * (y - x**2)**2

resultado = algoritmo_genetico(
    funcion_objetivo=rosenbrock,
    dimensiones=2,  # Dos variables
    limites=[(-5, 5), (-5, 5)],  # L√≠mites para x e y
    tamano_poblacion=100,
    max_generaciones=200,
    prob_mutacion=0.1
)
```

### En Google Colab

```python
# Instalar desde TestPyPI
!pip install --index-url https://test.pypi.org/simple/ --no-deps algoritmo_genetico_itomoei
!pip install numpy

# Importar y usar
from genetic_algorithm import algoritmo_genetico
```

## üß™ Ejemplos

### Ejemplo 1: Funci√≥n de una variable

```python
def funcion_cuadratica(x):
    return x[0]**2

resultado = algoritmo_genetico(
    funcion_objetivo=funcion_cuadratica,
    dimensiones=1,
    limites=[(-10, 10)],
    tamano_poblacion=50,
    max_generaciones=50
)
```

### Ejemplo 2: Maximizaci√≥n

```python
def funcion_para_maximizar(x):
    return -(x[0] - 5)**2 + 25  # M√°ximo en x=5 con valor 25

resultado = algoritmo_genetico(
    funcion_objetivo=funcion_para_maximizar,
    dimensiones=1,
    limites=[(-10, 20)],
    minimizar=False
)
```

### Ejemplo 3: Funci√≥n compleja

```python
def funcion_compleja(x):
    return x[0]**4 - 16*x[0]**2 + 5*x[0]  # Funci√≥n con m√∫ltiples √≥ptimos locales

resultado = algoritmo_genetico(
    funcion_objetivo=funcion_compleja,
    dimensiones=1,
    limites=[(-10, 10)],
    tamano_poblacion=100,
    max_generaciones=200
)
```

### Ejemplo 4: Multivariable

```python
def suma_cuadrados(variables):
    return sum(x**2 for x in variables)

resultado = algoritmo_genetico(
    funcion_objetivo=suma_cuadrados,
    dimensiones=5,  # 5 variables
    limites=[(-10, 10)]*5,  # Mismo l√≠mite para cada variable
    tamano_poblacion=200,
    max_generaciones=200
)
```

## üìñ API de Referencia

### algoritmo_genetico

```python
def algoritmo_genetico(
    funcion_objetivo, 
    dimensiones, 
    limites, 
    tamano_poblacion=100, 
    max_generaciones=100, 
    prob_cruce=0.8, 
    prob_mutacion=0.1, 
    minimizar=True, 
    tolerancia=1e-6, 
    generaciones_sin_mejora=20, 
    verbose=False
)
```

#### Par√°metros:

| Par√°metro | Tipo | Descripci√≥n |
|-----------|------|-------------|
| `funcion_objetivo` | Callable | Funci√≥n a optimizar. Debe aceptar un array numpy de tama√±o `dimensiones` |
| `dimensiones` | int | N√∫mero de variables de la funci√≥n |
| `limites` | List[Tuple[float, float]] | Lista de tuplas (min, max) para cada dimensi√≥n |
| `tamano_poblacion` | int | N√∫mero de individuos en la poblaci√≥n |
| `max_generaciones` | int | N√∫mero m√°ximo de generaciones |
| `prob_cruce` | float | Probabilidad de cruce (entre 0 y 1) |
| `prob_mutacion` | float | Probabilidad de mutaci√≥n (entre 0 y 1) |
| `minimizar` | bool | Si es True, minimiza la funci√≥n; si es False, maximiza |
| `tolerancia` | float | Tolerancia para convergencia |
| `generaciones_sin_mejora` | int | N√∫mero de generaciones sin mejora para detener |
| `verbose` | bool | Si es True, muestra informaci√≥n del progreso |

#### Retorno:

Un diccionario con:
- `mejor_solucion`: Array con la mejor soluci√≥n encontrada
- `mejor_valor`: Valor de la funci√≥n objetivo para la mejor soluci√≥n
- `generaciones`: N√∫mero de generaciones ejecutadas
- `historial_aptitudes`: Lista con los mejores valores en cada generaci√≥n
- `convergencia`: Boolean indicando si el algoritmo convergi√≥

### Funciones auxiliares

```python
crear_individuo(dimensiones, limites)
crear_poblacion(tamano_poblacion, dimensiones, limites)
evaluar_poblacion(poblacion, funcion_objetivo, minimizar)
seleccion_torneo(poblacion, aptitudes, tamano_torneo=3)
cruce(padre1, padre2, prob_cruce=0.8)
mutacion(individuo, limites, prob_mutacion=0.1)
```

## ‚öì Ajuste de Par√°metros

### Tama√±o de poblaci√≥n

- **Poblaciones peque√±as** (20-50):
  - ‚úÖ R√°pidas de evaluar
  - ‚úÖ Convergen r√°pido
  - ‚ùå Menor diversidad gen√©tica
  - ‚ùå Mayor riesgo de √≥ptimos locales

- **Poblaciones grandes** (100-500):
  - ‚úÖ Mayor diversidad gen√©tica
  - ‚úÖ Mejor exploraci√≥n del espacio
  - ‚ùå M√°s costosas computacionalmente
  - ‚ùå Convergencia m√°s lenta

### Probabilidad de cruce

- **Probabilidad alta** (0.8-1.0):
  - Favorece la exploraci√≥n
  - √ötil para problemas complejos

- **Probabilidad baja** (0.2-0.5):
  - Favorece la explotaci√≥n
  - √ötil cuando se est√° cerca del √≥ptimo

### Probabilidad de mutaci√≥n

- **Probabilidad alta** (0.1-0.3):
  - Mayor exploraci√≥n
  - Evita convergencia prematura
  - √ötil para escapar de √≥ptimos locales

- **Probabilidad baja** (0.01-0.05):
  - Refinamiento fino de soluciones
  - Mayor estabilidad
  - √ötil en las etapas finales

### Criterios de parada

- `max_generaciones`: L√≠mite duro de iteraciones
- `generaciones_sin_mejora`: Detiene cuando no hay progreso
- `tolerancia`: Define qu√© se considera una mejora significativa

## üîß Casos de Uso Avanzados

### Optimizaci√≥n con restricciones

Para problemas con restricciones, modifica la funci√≥n objetivo para penalizar soluciones inv√°lidas:

```python
def funcion_con_restricciones(x):
    # Funci√≥n original
    resultado = x[0]**2 + x[1]**2
    
    # Restricci√≥n: x[0] + x[1] <= 1
    if x[0] + x[1] > 1:
        # Penalizaci√≥n
        resultado += 1000 * (x[0] + x[1] - 1)**2
    
    return resultado
```

### Optimizaci√≥n de m√∫ltiples funciones objetivo

Para problemas multi-objetivo, puedes combinar las funciones con pesos:

```python
def funcion_multi_objetivo(x):
    # Minimizar x^2 y maximizar cos(x) simult√°neamente
    f1 = x[0]**2  # Minimizar
    f2 = -np.cos(x[0])  # Minimizar (equivale a maximizar cos(x))
    
    # Ponderaci√≥n de objetivos (puedes ajustar los pesos)
    return 0.7 * f1 + 0.3 * f2
```

### Optimizaci√≥n de hiperpar√°metros

Puedes usar algoritmos gen√©ticos para optimizar hiperpar√°metros de modelos ML:

```python
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris

# Cargar datos
iris = load_iris()
X, y = iris.data, iris.target

def optimizar_hiperparametros(parametros):
    # Convertir a valores enteros/discretos apropiados
    n_estimators = int(parametros[0])
    max_depth = int(parametros[1])
    min_samples_split = int(parametros[2])
    
    # Crear modelo con estos hiperpar√°metros
    modelo = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        random_state=42
    )
    
    # Evaluar con validaci√≥n cruzada
    scores = cross_val_score(modelo, X, y, cv=5)
    
    # Retornar el negativo (porque estamos minimizando)
    return -scores.mean()

# L√≠mites para los hiperpar√°metros
limites = [
    (10, 200),    # n_estimators
    (1, 20),      # max_depth
    (2, 10)       # min_samples_split
]

resultado = algoritmo_genetico(
    funcion_objetivo=optimizar_hiperparametros,
    dimensiones=3,
    limites=limites,
    tamano_poblacion=30,
    max_generaciones=20
)
```

## üìä Visualizaciones

### Visualizaci√≥n 2D simple

```python
import matplotlib.pyplot as plt
import numpy as np

# Luego de ejecutar el algoritmo:
def graficar_funcion_1d(funcion, limites, resultado):
    x = np.linspace(limites[0][0], limites[0][1], 1000)
    y = [funcion(np.array([xi])) for xi in x]
    
    plt.figure(figsize=(10, 6))
    plt.plot(x, y, 'b-', label='Funci√≥n objetivo')
    plt.scatter(resultado['mejor_solucion'][0], resultado['mejor_valor'], 
                color='red', s=100, marker='*', label='Mejor soluci√≥n')
    
    plt.title('Optimizaci√≥n mediante Algoritmo Gen√©tico')
    plt.xlabel('x')
    plt.ylabel('f(x)')
    plt.grid(True)
    plt.legend()
    plt.show()
```

### Visualizaci√≥n de convergencia

```python
def graficar_convergencia(historial_aptitudes):
    plt.figure(figsize=(10, 6))
    plt.plot(historial_aptitudes)
    plt.title('Convergencia del Algoritmo Gen√©tico')
    plt.xlabel('Generaci√≥n')
    plt.ylabel('Mejor aptitud')
    plt.grid(True)
    plt.show()
```

### Visualizaci√≥n 3D para funciones multivariable

```python
from mpl_toolkits.mplot3d import Axes3D

def graficar_funcion_2d(funcion, limites, resultado):
    fig = plt.figure(figsize=(12, 8))
    ax = fig.add_subplot(111, projection='3d')
    
    # Crear malla
    x = np.linspace(limites[0][0], limites[0][1], 100)
    y = np.linspace(limites[1][0], limites[1][1], 100)
    X, Y = np.meshgrid(x, y)
    
    # Calcular valores de Z
    Z = np.zeros_like(X)
    for i in range(len(x)):
        for j in range(len(y)):
            Z[j, i] = funcion(np.array([X[j, i], Y[j, i]]))
    
    # Graficar superficie
    surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8, 
                           linewidth=0, antialiased=True)
    
    # Marcar la mejor soluci√≥n
    mejor_x, mejor_y = resultado['mejor_solucion']
    mejor_z = resultado['mejor_valor']
    ax.scatter(mejor_x, mejor_y, mejor_z, color='red', s=100, marker='*', 
               label='Mejor soluci√≥n')
    
    # Configuraci√≥n del gr√°fico
    ax.set_title('Superficie de la funci√≥n objetivo')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('f(X,Y)')
    ax.legend()
    
    # Agregar barra de color
    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)
    plt.show()
```

## ü§ù Contribuir

¬°Las contribuciones son bienvenidas! Pasos para contribuir:

1. Fork del repositorio
2. Crear una rama para tu funcionalidad (`git checkout -b nueva-funcionalidad`)
3. Haz commit de tus cambios (`git commit -m 'A√±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin nueva-funcionalidad`)
5. Abrir un Pull Request

### Ideas para contribuciones:

- Implementar m√°s operadores de selecci√≥n (ruleta, elitista)
- A√±adir m√°s operadores de cruce (varios puntos, uniforme)
- Optimizaci√≥n para problemas con variables discretas
- Paralelizaci√≥n para poblaciones grandes
- M√©todos adaptativos para probabilidades de cruce y mutaci√≥n

## üë§ Autores

- **Bryan Rojas** - [GitHub](https://github.com/ITomoeI) - brrojas.h14@gmail.com
- **Juan Ayala**

## üìÑ Licencia

Este proyecto est√° licenciado bajo la Licencia MIT - vea el archivo [LICENSE](LICENSE) para m√°s detalles.

---

## üìö Referencias

- Goldberg, D. E. (1989). *Genetic Algorithms in Search, Optimization, and Machine Learning*. Addison-Wesley.
- Mitchell, M. (1998). *An Introduction to Genetic Algorithms*. MIT Press.
- Holland, J. H. (1992). *Adaptation in Natural and Artificial Systems*. MIT Press.
